print(e)
browser()
})
test.real   <- as.numeric(test.rows$Regime)
test.pr     <- as.numeric(predictions)
avg.RMSE = avg.RMSE + sqrt(mean((test.real - test.pr)^2))
}
avg.RMSE <- avg.RMSE / folds
print(paste('Average:', avg.RMSE))
if(avg.RMSE < prev.RMSE) {
features.order <- feats
prev.RMSE <- avg.RMSE
print('Updated!')
}
}
print(paste('Final features:', selected))
}
##----------LOAD DATA----------##
regime.table <- read_rds('Data.rds')
logged.table <- regime.table
logged.table[,names_times_x(10, 'GDPPerCapita')] <-
log(logged.table[,names_times_x(10, 'GDPPerCapita')])
logged.table[,names_times_x(10, 'Population')] <-
log(logged.table[,names_times_x(10, 'Population')])
logged.table <- logged.table
##----------SELECT FEATURES----------##
all_features <- names(logged.table)
# (1) 1,10; 2(2) 9,10; (3) 8,10; (4) 5,10; (5) 1-10; (6) 1-5
selections <- list(c(all_features[grepl('.+(1|10)', all_features)]),
c(all_features[grepl('.+(9|10)', all_features)]),
c(all_features[grepl('.+(8|10)', all_features)]),
c(all_features[grepl('[a-zA-Z](6.)*(5|10)', all_features)]),
c(all_features[grepl('.+[0-9]', all_features)]),
c(all_features[grepl('.+[1-5]$', all_features)]))
selections <- lapply(selections, function(x) { c(all_features[c(1:4)], x) })
models <- numeric( length(selections) )
folds = 5
for(i in 1:length(selections)) {
selected <- logged.table[, selections[[i]]]
features.order <- names(selected)[sample(length(selected))]
features.order <- c('', features.order[features.order != 'Regime'])
print(paste0('-----------', i, '-----------'))
models[[i]] <- back_step.cv.polr(folds, features.order, selected)
}
# selected <- logged.table[, selections[[1]]]
# x <- polr(Regime ~ ., data = selected)
# y <- stepAIC(x)
help(glment)
help(glmnet)
View(selected)
row.order  <- sample(nrow(selected))
train.rows <- selected[ head(row.order, nrow(selected)*0.8), ]
test.rows  <- selected[ tail(row.order, -nrow(selected)*0.8), ]
view(train.rows)
x <- model.matrix(Regime ~ ., train.rows)
View(x)
View(x[,-1])
x <- model.matrix(Regime ~ ., train.rows)[,-1]
y <- train.rows$Regime
m <- glmnet(x, y, family = 'binomial')
m <- glmnet(x, y, family = 'multinomial')
summary(m)
m <- glmnetcr(x, y, family = 'multinomial')
m <- glmnetcr(x, y)
############
# - Use cross validation to determine ideal window size for time series prediction
#    - Check maybe 1 and 10 to remove colinearity that would prob be apparent
#      from 1/2/3 etc. (directly one after the other)
# - There will be lots of colinearity -- check
# - Need some sort of regularization -- Lasso, Ridge, PCA -- to deal with colinearity
# - Might be worth looking at CHANGES from year to year
# - Best things to look at: overall trends, close change, lag
# - Evaluate the predictors and window size simultaneously
# - Use ordinal logistic regression -- glmnetcr
############
##----------PREP----------##
library(MASS)
library(glmnetcr)
library(tidyverse)
set.seed(39415)
##----------FUNCTIONS----------##
names_times_x <- function(x, col_names) {
new_names <- c()
for(i in 1:x) {
names_x <- paste0(col_names, i)
new_names <- c(new_names, names_x)
}
return(new_names)
}
back_step.cv.polr <- function(folds, features.order, df, train_size = 0.8) {
rows <- nrow(df)
prev.RMSE <- Inf
for(feat in features.order) {
avg.RMSE <- 0
feats  <- features.order[features.order != feat]
sub.df <- df[c('Regime', feats)] %>% mutate(Regime = as.numeric(Regime))
print(feats)
for(i in 1:folds) {
print(i)
row.order  <- sample(rows)
train.rows <- sub.df[ head(row.order, nrow(sub.df)*train_size), ]
test.rows  <- sub.df[ tail(row.order, -nrow(sub.df)*train_size), ]
###curr.model <- polr(Regime ~ ., train.rows)
curr.model <- lm(Regime ~ ., train.rows)
# Fill out the factor levels that were not used during training
#curr.model$xlevels$Entity <- levels(df$Entity)
# If coefficients were eliminated in the model because of colinearity,
# drop the corresponding columns from the test rows
# used.cols <- names(curr.model$coefficients)[!grepl('Entity', names(curr.model$coefficients))]
# if('Entity' %in% names(test.rows))
#   used.cols <- c(used.cols, 'Entity')
# test.rows <- test.rows[, c(used.cols, 'Regime')]
tryCatch({
predictions <- predict(curr.model, test.rows, type = 'class')
}, error = function(e) {
print(e)
browser()
})
test.real   <- as.numeric(test.rows$Regime)
test.pr     <- as.numeric(predictions)
avg.RMSE = avg.RMSE + sqrt(mean((test.real - test.pr)^2))
}
avg.RMSE <- avg.RMSE / folds
print(paste('Average:', avg.RMSE))
if(avg.RMSE < prev.RMSE) {
features.order <- feats
prev.RMSE <- avg.RMSE
print('Updated!')
}
}
print(paste('Final features:', selected))
}
##----------LOAD DATA----------##
regime.table <- read_rds('Data.rds')
logged.table <- regime.table
logged.table[,names_times_x(10, 'GDPPerCapita')] <-
log(logged.table[,names_times_x(10, 'GDPPerCapita')])
logged.table[,names_times_x(10, 'Population')] <-
log(logged.table[,names_times_x(10, 'Population')])
logged.table <- logged.table
##----------SELECT FEATURES----------##
all_features <- names(logged.table)
# (1) 1,10; 2(2) 9,10; (3) 8,10; (4) 5,10; (5) 1-10; (6) 1-5
selections <- list(c(all_features[grepl('.+(1|10)', all_features)]),
c(all_features[grepl('.+(9|10)', all_features)]),
c(all_features[grepl('.+(8|10)', all_features)]),
c(all_features[grepl('[a-zA-Z](6.)*(5|10)', all_features)]),
c(all_features[grepl('.+[0-9]', all_features)]),
c(all_features[grepl('.+[1-5]$', all_features)]))
selections <- lapply(selections, function(x) { c(all_features[c(1:4)], x) })
models <- numeric( length(selections) )
folds = 5
for(i in 1:length(selections)) {
selected <- logged.table[, selections[[i]]]
features.order <- names(selected)[sample(length(selected))]
features.order <- c('', features.order[features.order != 'Regime'])
print(paste0('-----------', i, '-----------'))
models[[i]] <- back_step.cv.polr(folds, features.order, selected)
}
# selected <- logged.table[, selections[[1]]]
# x <- polr(Regime ~ ., data = selected)
# y <- stepAIC(x)
############
# - Use cross validation to determine ideal window size for time series prediction
#    - Check maybe 1 and 10 to remove colinearity that would prob be apparent
#      from 1/2/3 etc. (directly one after the other)
# - There will be lots of colinearity -- check
# - Need some sort of regularization -- Lasso, Ridge, PCA -- to deal with colinearity
# - Might be worth looking at CHANGES from year to year
# - Best things to look at: overall trends, close change, lag
# - Evaluate the predictors and window size simultaneously
# - Use ordinal logistic regression -- glmnetcr
############
##----------PREP----------##
library(MASS)
library(glmnetcr)
library(tidyverse)
set.seed(39415)
##----------FUNCTIONS----------##
names_times_x <- function(x, col_names) {
new_names <- c()
for(i in 1:x) {
names_x <- paste0(col_names, i)
new_names <- c(new_names, names_x)
}
return(new_names)
}
back_step.cv.polr <- function(folds, features.order, df, train_size = 0.8) {
rows <- nrow(df)
prev.RMSE <- Inf
for(feat in features.order) {
avg.RMSE <- 0
feats  <- features.order[features.order != feat]
sub.df <- df[c('Regime', feats)] %>% mutate(Regime = as.numeric(Regime))
print(feats)
for(i in 1:folds) {
print(i)
row.order  <- sample(rows)
train.rows <- sub.df[ head(row.order, nrow(sub.df)*train_size), ]
test.rows  <- sub.df[ tail(row.order, -nrow(sub.df)*train_size), ]
###curr.model <- polr(Regime ~ ., train.rows)
curr.model <- lm(Regime ~ ., train.rows)
# Fill out the factor levels that were not used during training
#curr.model$xlevels$Entity <- levels(df$Entity)
# If coefficients were eliminated in the model because of colinearity,
# drop the corresponding columns from the test rows
# used.cols <- names(curr.model$coefficients)[!grepl('Entity', names(curr.model$coefficients))]
# if('Entity' %in% names(test.rows))
#   used.cols <- c(used.cols, 'Entity')
# test.rows <- test.rows[, c(used.cols, 'Regime')]
tryCatch({
predictions <- predict(curr.model, test.rows)
}, error = function(e) {
print(e)
browser()
})
test.real   <- as.numeric(test.rows$Regime)
test.pr     <- as.numeric(predictions)
avg.RMSE = avg.RMSE + sqrt(mean((test.real - test.pr)^2))
}
avg.RMSE <- avg.RMSE / folds
print(paste('Average:', avg.RMSE))
if(avg.RMSE < prev.RMSE) {
features.order <- feats
prev.RMSE <- avg.RMSE
print('Updated!')
}
}
print(paste('Final features:', selected))
}
##----------LOAD DATA----------##
regime.table <- read_rds('Data.rds')
logged.table <- regime.table
logged.table[,names_times_x(10, 'GDPPerCapita')] <-
log(logged.table[,names_times_x(10, 'GDPPerCapita')])
logged.table[,names_times_x(10, 'Population')] <-
log(logged.table[,names_times_x(10, 'Population')])
logged.table <- logged.table
##----------SELECT FEATURES----------##
all_features <- names(logged.table)
# (1) 1,10; 2(2) 9,10; (3) 8,10; (4) 5,10; (5) 1-10; (6) 1-5
selections <- list(c(all_features[grepl('.+(1|10)', all_features)]),
c(all_features[grepl('.+(9|10)', all_features)]),
c(all_features[grepl('.+(8|10)', all_features)]),
c(all_features[grepl('[a-zA-Z](6.)*(5|10)', all_features)]),
c(all_features[grepl('.+[0-9]', all_features)]),
c(all_features[grepl('.+[1-5]$', all_features)]))
selections <- lapply(selections, function(x) { c(all_features[c(1:4)], x) })
models <- numeric( length(selections) )
folds = 5
for(i in 1:length(selections)) {
selected <- logged.table[, selections[[i]]]
features.order <- names(selected)[sample(length(selected))]
features.order <- c('', features.order[features.order != 'Regime'])
print(paste0('-----------', i, '-----------'))
models[[i]] <- back_step.cv.polr(folds, features.order, selected)
}
# selected <- logged.table[, selections[[1]]]
# x <- polr(Regime ~ ., data = selected)
# y <- stepAIC(x)
############
# - Use cross validation to determine ideal window size for time series prediction
#    - Check maybe 1 and 10 to remove colinearity that would prob be apparent
#      from 1/2/3 etc. (directly one after the other)
# - There will be lots of colinearity -- check
# - Need some sort of regularization -- Lasso, Ridge, PCA -- to deal with colinearity
# - Might be worth looking at CHANGES from year to year
# - Best things to look at: overall trends, close change, lag
# - Evaluate the predictors and window size simultaneously
# - Use ordinal logistic regression -- glmnetcr
############
##----------PREP----------##
library(MASS)
library(glmnetcr)
library(tidyverse)
set.seed(39415)
##----------FUNCTIONS----------##
names_times_x <- function(x, col_names) {
new_names <- c()
for(i in 1:x) {
names_x <- paste0(col_names, i)
new_names <- c(new_names, names_x)
}
return(new_names)
}
back_step.cv.polr <- function(folds, features.order, df, train_size = 0.8) {
rows <- nrow(df)
prev.RMSE <- Inf
for(feat in features.order) {
avg.RMSE <- 0
feats  <- features.order[features.order != feat]
sub.df <- df[c('Regime', feats)]
print(feats)
for(i in 1:folds) {
print(i)
row.order  <- sample(rows)
train.rows <- sub.df[ head(row.order, nrow(sub.df)*train_size), ]
test.rows  <- sub.df[ tail(row.order, -nrow(sub.df)*train_size), ]
curr.model <- polr(Regime ~ ., train.rows)
# Fill out the factor levels that were not used during training
#curr.model$xlevels$Entity <- levels(df$Entity)
# If coefficients were eliminated in the model because of colinearity,
# drop the corresponding columns from the test rows
# used.cols <- names(curr.model$coefficients)[!grepl('Entity', names(curr.model$coefficients))]
# if('Entity' %in% names(test.rows))
#   used.cols <- c(used.cols, 'Entity')
# test.rows <- test.rows[, c(used.cols, 'Regime')]
tryCatch({
predictions <- predict(curr.model, test.rows, type = 'class')
}, error = function(e) {
print(e)
browser()
})
test.real   <- as.numeric(test.rows$Regime)
test.pr     <- as.numeric(predictions)
avg.RMSE = avg.RMSE + sqrt(mean((test.real - test.pr)^2))
}
avg.RMSE <- avg.RMSE / folds
print(paste('Average:', avg.RMSE))
if(avg.RMSE < prev.RMSE) {
features.order <- feats
prev.RMSE <- avg.RMSE
print('Updated!')
}
}
print(paste('Final features:', selected))
}
back_step.cv.lm <- function(folds, features.order, df, train_size = 0.8) {
rows <- nrow(df)
prev.RMSE <- Inf
for(feat in features.order) {
avg.RMSE <- 0
feats  <- features.order[features.order != feat]
sub.df <- df[c('Regime', feats)] %>% mutate(Regime = as.numeric(Regime))
print(feats)
for(i in 1:folds) {
print(i)
row.order  <- sample(rows)
train.rows <- sub.df[ head(row.order, nrow(sub.df)*train_size), ]
test.rows  <- sub.df[ tail(row.order, -nrow(sub.df)*train_size), ]
curr.model <- lm(Regime ~ ., train.rows)
# Fill out the factor levels that were not used during training
curr.model$xlevels$Entity <- levels(df$Entity)
predictions <- predict(curr.model, test.rows, type = 'class')
avg.RMSE = avg.RMSE + sqrt(mean((test.rows$Regime - predictions)^2))
}
avg.RMSE <- avg.RMSE / folds
print(paste('Average:', avg.RMSE))
if(avg.RMSE < prev.RMSE) {
features.order <- feats
prev.RMSE <- avg.RMSE
print('Updated!')
}
}
print(paste('Final features:', selected))
}
##----------LOAD DATA----------##
regime.table <- read_rds('Data.rds')
logged.table <- regime.table
logged.table[,names_times_x(10, 'GDPPerCapita')] <-
log(logged.table[,names_times_x(10, 'GDPPerCapita')])
logged.table[,names_times_x(10, 'Population')] <-
log(logged.table[,names_times_x(10, 'Population')])
logged.table <- logged.table
##----------SELECT FEATURES----------##
all_features <- names(logged.table)
# (1) 1,10; 2(2) 9,10; (3) 8,10; (4) 5,10; (5) 1-10; (6) 1-5
selections <- list(c(all_features[grepl('.+(1|10)', all_features)]),
c(all_features[grepl('.+(9|10)', all_features)]),
c(all_features[grepl('.+(8|10)', all_features)]),
c(all_features[grepl('[a-zA-Z](6.)*(5|10)', all_features)]),
c(all_features[grepl('.+[0-9]', all_features)]),
c(all_features[grepl('.+[1-5]$', all_features)]))
selections <- lapply(selections, function(x) { c(all_features[c(1:4)], x) })
models <- numeric( length(selections) )
folds = 5
for(i in 1:length(selections)) {
selected <- logged.table[, selections[[i]]]
features.order <- names(selected)[sample(length(selected))]
features.order <- c('', features.order[features.order != 'Regime'])
print(paste0('-----------', i, '-----------'))
models[[i]] <- back_step.cv.lm(folds, features.order, selected)
}
# selected <- logged.table[, selections[[1]]]
# x <- polr(Regime ~ ., data = selected)
# y <- stepAIC(x)
############
# - Use cross validation to determine ideal window size for time series prediction
#    - Check maybe 1 and 10 to remove colinearity that would prob be apparent
#      from 1/2/3 etc. (directly one after the other)
# - There will be lots of colinearity -- check
# - Need some sort of regularization -- Lasso, Ridge, PCA -- to deal with colinearity
# - Might be worth looking at CHANGES from year to year
# - Best things to look at: overall trends, close change, lag
# - Evaluate the predictors and window size simultaneously
# - Use ordinal logistic regression -- glmnetcr
############
##----------PREP----------##
library(MASS)
library(glmnetcr)
library(tidyverse)
set.seed(39415)
##----------FUNCTIONS----------##
names_times_x <- function(x, col_names) {
new_names <- c()
for(i in 1:x) {
names_x <- paste0(col_names, i)
new_names <- c(new_names, names_x)
}
return(new_names)
}
back_step.cv.polr <- function(folds, features.order, df, train_size = 0.8) {
rows <- nrow(df)
prev.RMSE <- Inf
for(feat in features.order) {
avg.RMSE <- 0
feats  <- features.order[features.order != feat]
sub.df <- df[c('Regime', feats)]
print(feats)
for(i in 1:folds) {
print(i)
row.order  <- sample(rows)
train.rows <- sub.df[ head(row.order, nrow(sub.df)*train_size), ]
test.rows  <- sub.df[ tail(row.order, -nrow(sub.df)*train_size), ]
curr.model <- polr(Regime ~ ., train.rows)
# Fill out the factor levels that were not used during training
#curr.model$xlevels$Entity <- levels(df$Entity)
# If coefficients were eliminated in the model because of colinearity,
# drop the corresponding columns from the test rows
# used.cols <- names(curr.model$coefficients)[!grepl('Entity', names(curr.model$coefficients))]
# if('Entity' %in% names(test.rows))
#   used.cols <- c(used.cols, 'Entity')
# test.rows <- test.rows[, c(used.cols, 'Regime')]
tryCatch({
predictions <- predict(curr.model, test.rows, type = 'class')
}, error = function(e) {
print(e)
browser()
})
test.real   <- as.numeric(test.rows$Regime)
test.pr     <- as.numeric(predictions)
avg.RMSE = avg.RMSE + sqrt(mean((test.real - test.pr)^2))
}
avg.RMSE <- avg.RMSE / folds
print(paste('Average:', avg.RMSE))
if(avg.RMSE < prev.RMSE) {
features.order <- feats
prev.RMSE <- avg.RMSE
print('Updated!')
}
}
print(paste('Final features:', features.order))
}
back_step.cv.lm <- function(folds, features.order, df, train_size = 0.8) {
rows <- nrow(df)
prev.RMSE <- Inf
for(feat in features.order) {
avg.RMSE <- 0
feats  <- features.order[features.order != feat]
sub.df <- df[c('Regime', feats)] %>% mutate(Regime = as.numeric(Regime))
print(feats)
for(i in 1:folds) {
print(i)
row.order  <- sample(rows)
train.rows <- sub.df[ head(row.order, nrow(sub.df)*train_size), ]
test.rows  <- sub.df[ tail(row.order, -nrow(sub.df)*train_size), ]
curr.model <- lm(Regime ~ ., train.rows)
# Fill out the factor levels that were not used during training
curr.model$xlevels$Entity <- levels(df$Entity)
predictions <- predict(curr.model, test.rows, type = 'class')
avg.RMSE = avg.RMSE + sqrt(mean((test.rows$Regime - predictions)^2))
}
avg.RMSE <- avg.RMSE / folds
print(paste('Average:', avg.RMSE))
if(avg.RMSE < prev.RMSE) {
features.order <- feats
prev.RMSE <- avg.RMSE
print('Updated!')
}
}
print(paste('Final features:', features.order))
}
##----------LOAD DATA----------##
regime.table <- read_rds('Data.rds')
logged.table <- regime.table
logged.table[,names_times_x(10, 'GDPPerCapita')] <-
log(logged.table[,names_times_x(10, 'GDPPerCapita')])
logged.table[,names_times_x(10, 'Population')] <-
log(logged.table[,names_times_x(10, 'Population')])
logged.table <- logged.table
##----------SELECT FEATURES----------##
all_features <- names(logged.table)
# (1) 1,10; 2(2) 9,10; (3) 8,10; (4) 5,10; (5) 1-10; (6) 1-5
selections <- list(c(all_features[grepl('.+(1|10)', all_features)]),
c(all_features[grepl('.+(9|10)', all_features)]),
c(all_features[grepl('.+(8|10)', all_features)]),
c(all_features[grepl('[a-zA-Z](6.)*(5|10)', all_features)]),
c(all_features[grepl('.+[0-9]', all_features)]),
c(all_features[grepl('.+[1-5]$', all_features)]))
selections <- lapply(selections, function(x) { c(all_features[c(1:4)], x) })
models <- numeric( length(selections) )
folds = 5
for(i in 1:length(selections)) {
selected <- logged.table[, selections[[i]]]
features.order <- names(selected)[sample(length(selected))]
features.order <- c('', features.order[features.order != 'Regime'])
print(paste0('-----------', i, '-----------'))
models[[i]] <- back_step.cv.lm(folds, features.order, selected)
}
# selected <- logged.table[, selections[[1]]]
# x <- polr(Regime ~ ., data = selected)
# y <- stepAIC(x)
